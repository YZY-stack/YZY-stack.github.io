---
layout: default
---


<style type="text/css">
    .container{
      margin: 0 auto;
      width: 100%;
      max-width: 900px !important;
    }
    body{
        font-weight: 200;
        font-size: 16px;
        /*background-color: rgb(43, 60, 197);*/
        /*color: rgb(0, 79, 241);*/
        /*color: white;*/
        border-top:5px solid rgba(202, 202, 202, 0.588);
        border-bottom:5px solid rgba(202, 202, 202, 0.588);
    }
    b{
      color:rgb(0, 79, 241);
    }
    .posts{
        /*font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;*/
        font-size: 14px;

    }
    .news{
      line-height: 1.5em;
    }
    .post{
      border-left: 5px solid rgba(202, 202, 202, 0.588);
    }
    .xtitle{
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
        font-size: 24px;
        margin: 10px 0;
        color:rgb(0, 79, 241);
    }
    
    .posts .teaser{
      align:center;
      width: 100%;
/*      height: 20%;*/
      overflow: hidden;
/*        width: 200px;*/
/*        height: 350px;*/
        height: 50%;
        float: left;
        margin: 0 0 0 10px;
    }

    .posts .teaser-left{
    margin: 0 auto;
    max-width:300px;
    max-height:150px;
    display: block;
    width: auto;
    height: auto;
    }

    .teaser-container{
    float: left;
    width: 300px;  
    height: 180px;

    margin-right: 20px;  
    margin-left: 20px;  
    }

    .post-hidden{
      display: none;
    }

    a{
      color: #111;
      position: relative;
    }
    a:after{
      content: '';
      position: absolute;
      top: 60%;
      left: -0.1em;
      right: -0.1em;
      bottom: 0;
      transition:top 200ms cubic-bezier(0, 0.8, 0.13, 1);
      /*background-color: rgba(225, 166, 121, 0.5);*/
      background-color: rgba(255, 210, 30, 0.346);
    }

    .emojilink:after{
      background-color: rgba(255,211,30, 0.0) 
      /*rgba(225, 166, 121, 0.0);*/
    }
    a:hover{
      color:rgb(180, 255, 248);
    }
    a:hover:after{
      color:rgb(180, 255, 248);
      /*color: #111;*/
      top:0%;
    }
    .xcode a:after{
      content: '';
      position: absolute;
      top: 100%;
      left: 0;
      right: 0;
      bottom: 0;
      transition:top 200ms cubic-bezier(0, 0.8, 0.13, 1);
      /*background-color: rgba(225, 166, 121, 0.5);*/
      background-color: #fff;
    }
    .xcode a:hover:after{
      color: #fff;
      /*color: #111;*/
    }
    .entry{
        position: relative;
        top:0;
        left: 20px;
        margin-top: 5px;
    }

    .posts > .post{
        border-bottom: 0;
        padding-bottom:0em;
        padding-top: 10px;
        margin-bottom: 10px;
    }
    .papertitle{
        margin-top: 0px;
        font-weight: 600;
        font-size:16px;
        font-style: italic;
        /*font-style: italic;*/
        /*height: 2.6em*/
    }

</style>

<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<script type="text/javascript">

$(function(){
    $('#vis_teaser').on('click', function(){
        $('.unimportant').toggleClass('post-hidden')
   });
});
</script>

<div>
  
<img style="width: 90px;float: left;" src="images/zhiyuan_jinmen.jpg">

<div style="position: relative; left:20px;">
<div style="font-size:24px;font-weight: 300">Zhiyuan Yan</div>
<div>üìñ Second-year PhD Student</div>
<div>üè´ Peking University, previously at CUHK-SZ</div>
<div>üí° Multimodal, Vision Language Model, AIGC Detection, AI4Science</div>
<a href="yanzhiyuan1114@gmail.com">Email</a> / <a target="_blank" href="https://github.com/YZY-stack">Github</a> / <a target="_blank" href="https://scholar.google.com/citations?user=U_u-mvoAAAAJ&hl=zh-CN">Scholar</a> / <a target="_blank" href="https://openreview.net/profile?id=~Zhiyuan_Yan3">OpenReview</a></a>
  
</div>

</div>


<div id="Biography" class='xtitle' >Biography</div>
<div style="text-align: justify;clear: both;">
         <li> <strong>I am a second-year PhD Student in computer science at Peking University (PKU)</strong>, supervised by Prof. <a href="https://yuanli2333.github.io/" target="_blank">Li Yuan</a> (Deep Learning) and Prof. <a href="http://www2.coe.pku.edu.cn/faculty/mofanyang/index.html" target="_blank">Fanyang Mo</a> (AI4Science). I have published over 10 papers (first/co-first author) at the top international AI conferences with a total <a href="https://scholar.google.com/citations?hl=zh-CN&user=U_u-mvoAAAAJ&view_op=list_works&gmla=AJsN-F7ZS4Gf2DOKKXebzMGIrUkUPHEvZl9nnvSbxkbgN5LFi7I_JZxks2fG9J8LcREkgey5zn-YJsCW1_DMCxQfRDX7ELGJc3VwMO6Skg7yfiL9yzaP-74" target="_blank">Google Scholar</a> citations of 1000+. I am now a research intern for multimodal generation at the Baidu ERNIE team through the "ERNIE Star Program", under the supervision of <a href="https://jingdongwang2017.github.io/" target="_blank">Jingdong Wang</a> and <a href="https://haifengwang.net/" target="_blank">Haifeng Wang</a>.

 </li> 
    <br/>
    <li> My current <strong>research interests</strong> are: <strong>(1) Multimodal, especially unified multimodal generation and understanding</strong>: I'm deeply researching the hybrid architecture of autoregressive (AR) and diffusion models, and have developed a thorough understanding and thoughtful insights into their complementary mechanisms, architectural design, and joint training strategies, with the goal of advancing unified multimodal understanding and generation. </li>
    
    <li><strong> (2) AI4Science</strong>: Utilizing DL/ML methods or the latest reasoning models to address challenges in the science topics, especially chemistry and drug discovery. I believe that interdisciplinary cross-pollination and integration can spark new insights and innovative thinking. </li>

    <li> <strong>My previous research direction is: AIGC Detection and Deepfake detection</strong>: I have developed generalizable and interpretable methods for detecting AI-generated images and videos, and also the first and most comprehensive benchmark (DeepfakeBench) in the field. </li>
    <br/>
    <br/>
    If you are interested in my work and would like to cooperate with me, please do not hesitate to contact!
    <br/>    
</div>

<!-- 
<div id="Latest News" class='xtitle'  >News</div>
<ul class="news" style="line-height: 2em">
<li> [September 2025] <b>Seven papers are accepted by NeurIPS 2025</b>, covering image editing, visual perception, AIGC/deepfake detection, and AI4Science. Congrats to all collaborators! </li> </li>
<li> [September 2025] üö® Our latest work, <b>UAE, unifies multimodal generation and understanding in one RL-driven reconstruction loop, enabling each to strengthen the other.</b> Please check: <strong>[ </strong><a href="https://arxiv.org/abs/2509.09666" target="_blank">Paper</a>; <a href="https://huggingface.co/zhiyuanyan1/UAE" target="_blank">Dataset</a>; <a href="https://github.com/PKU-YuanGroup/UAE" target="_blank">Code</a> <strong>]</strong>. </li>
<li> [July 2025] I am happy to join the Baidu ERNIE team through the "ERNIE Star Top Talent Program", under the supervision of Haifeng Wang. </li>
<li> [May 2025] Two papers are accepted by <b>ICML 2025</b>, including one <b>Oral</b>üèÜ (<b>top 1%</b>)! </li>
<li> [April 2025] üö® Our work <b>GPT-ImgEval, a comprehensive benchmark for for diagnosing gpt4o in image generation</b> is now available! Please check: <strong>[ </strong><a href="https://arxiv.org/abs/2504.02782" target="_blank">Paper</a>; <a href="https://huggingface.co/datasets/Yejy53/GPT-ImgEval" target="_blank">Dataset</a>; <a href="https://github.com/PicoTrex/GPT-ImgEval" target="_blank">Code</a> <strong>]</strong>. </li>
<li> [February 2025] Two papers are accepted by <b>CVPR 2025</b>. Congrats to all collaborators! </li>
<li> [January 2025] One paper is accepted by <b>AAAI 2025 (Oral)</b>. Congrats to all collaborators! </li>
<!-- <li> [December 2024] I am invited as a journal reviewer of <i>TPAMI</i>. -->
<!-- <li> [September 2024] Two papers are accepted by <b>NeurIPS 2024</b>. Congrats to all collaborators! </li>
<li> [August 2024] We are excited to introduce our brand-new AI-generated face dataset called <b>DF40</b>, comprising 40 distinct generation methods. Please refer to the <a href="https://yzy-stack.github.io/homepage_for_df40" target="_blank">Project Page</a> for details. <div style="float: right;"></div> </li> -->
<!-- <li> [August 2024] I am invited as a journal reviewer of <i>TIFS</i> and <i>TCSVT</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [August 2024] I am invited as a reviewer of <i>ICLR 2025</i> and <i>AAAI 2025</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [May 2024] I am invited as a reviewer of both the main track and dataset & benchmark track of <i>NeurIPS 2024</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [April 2024] <a href="https://arxiv.org/abs/2403.14077/" target="_blank">The paper</a> on using ChatGPT-4V for detecting AI-synthesized images is accepted by CVPR 2024 Workshop on Media Forensics (WMF). <div style="float: right;"></div> </li> -->
<!-- <li> [February 2024] <a href="https://arxiv.org/abs/2304.13949/" target="_blank">The paper of LSDA</a> has been accepted by <b>CVPR 2024</b>: Augmenting different forgery types in the latent space to address the forgery-specific overfitting problem in deepfake detection. <div style="float: right;"></div> </li> -->
<!-- <li> [February 2024] I am invited as a reviewer of <i>ECCV 2024</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [October 2023] I am invited as a reviewer of <i>CVPR 2024</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [October 2023] I will go to Paris to attend <i>ICCV 2023</i>. <div style="float: right;"></div> </li> -->
<!-- <li> [September 2023] Our <a href="https://github.com/SCLBD/DeepfakeBench/" target="_blank">DeepfakeBench</a> has been accepted by <b>NeurIPS 2023</b>. <div style="float: right;"></div> </li>
<li> [July 2023] <a href="https://arxiv.org/abs/2304.13949/" target="_blank">The paper of UCF</a> has been accepted by <b>ICCV 2023</b>: A new disentanglement-based framework for more general deepfake detection. <div style="float: right;"></div> </li> -->
<!-- <!-- <li> [July 2023] Our <a href="https://github.com/SCLBD/DeepfakeBench/" target="_blank">DeepfakeBench</a>, a comprehensive open-source platform for deepfake detection, is now available! <div style="float: right;"></div> </li> -->
<!-- <li> [May 2022] Our <a href="https://academic.oup.com/bioinformatics/article/38/13/3444/6590643/" target="_blank">HelixADMET</a> has been published at <b>Bioinformatics journal</b>: a robust ADMET system for accurate drug screening and estimation of ADMET endpoints. <div style="float: right;"></div> </li> -->

<!-- </ul> -->
 -->


<div id="Research Highlights" class='xtitle' > Selected Publications <span style="color:#333;font-size: 14px; font-family: Helvetica, Arial, sans-serif; "> (üßë‚Äçüíª Co-first Author, üìÆ Corresponding Author) </span> <span style="color:#333;font-size: 14px; font-family: Helvetica, Arial, sans-serif; "> </span> </div> 


<div class="posts">
  {% for post in site.posts %}

    {% if post.is_show %}
    <article class="post">
 
    {% else %}
    <article class="post unimportant post-hidden">

    {% endif %}

      <!-- <div style="position: relative; left:-50px; font-size: 18px;">{{post.year}}</div> -->

      <!-- <div style="text-align:center;"><img class="teaser-img" src="{{post.teaser}}"> </div> -->

      <div class= "teaser-container">
        <img class="teaser-left"  src="{{post.teaser}}">
      </div>

      <div class= "papertitle entry" >{{ post.title }}</div>

      <div class="entry">
        {{ post.authors }}
      </div>

      <div class="entry">
          <i>{{post.publication}}</i>, <i>{{post.year}}</i>
          {% if post.journal%}
           /
            <i>{{post.journal}}</i>, <i>{{post.year}}</i>
          {% endif %}  
      </div>

      <div class="entry">
        
        {% if post.arxiv%}
        <a class='links' target="_blank" href="{{ post.arxiv_url }}" rel="paperurl">arXiv</a>
        {% endif %}       

        {% if post.extented_url%}
        /
        <a class='links' target="_blank" href="{{ post.extented_url }}" rel="paperurl">Extended Version</a>
        {% endif %}       
        
        {% if post.demo%}
        /
        <a class='links' target="_blank" href="{{ post.demo }}" rel="paperurl">Online Demo</a> 
        {% endif %}

        {% if post.project%}
        /
        <a class='links' target="_blank" href="{{ post.project }}" rel="paperurl">Project Page</a> 
        {% endif %}
        
        {% if post.code%} 
        /
        <a target="_blank" href="{{post.code}}">Github</a>
        {% endif %} 

        {% if post.code%} 
        <div style="display: inline-block;float:right" class="xcode">
        <!-- <a class="github-button" href="{{post.code}}" data-show-count="true">Star</a>  -->
        <a href="{{post.code}}"><img src="https://img.shields.io/github/stars/{{post.code| replace:'https://github.com/', ''}}?style=social"/></a>
        </div>
        {% endif %} 

        </div>
      <div style ="clear:both"></div>
      <!-- <a href="{{ site.baseurl }}{{ post.url }}" class="read-more">Read More</a> -->
    </article>
  {% endfor %}
</div>



<!-- 
<div id="Experience" class='xtitle' >Experience</div>
<ul class="news" style="list-style: 2em;">
<li>
    <i>Baidu ERNIE Team (ERNIE Star Top Talent Program)
</i> 
    <div style="float: right;">July 2025 - Now</div>  
    <p>Position: Research Intern for Multimodal Generation.</p>
</li>
<li>
    <i>Tencent YoutuLab</i> 
    <div style="float: right;">Jan 2024 - July 2025</div>  
    <p>Position: Researcher for AIGC/Face Detection and Multimodal Machine Learning.</p>
</li>
<li>
    <i>The Chinese University of Hong Kong, Shenzhen</i> 
    <div style="float: right;">Nov 2022 - Dec 2023</div>  
    <p>Position: Research Assistant, supervised by Prof. <a href="https://github.com/SCLBD/DeepfakeBench/" target="_blank">Baoyuan Wu</a>.</p> 
</li>
<li> 
    <i>Baidu NLP</i> 
    <div style="float: right;">Sep 2021 - Jun 2022</div> 
    <p>Position: Research Intern for AI4Science and NLP pre-training.
</li>
<li> 
    <i>DJI Technology Co., Ltd.</i> 
    <div style="float: right;">Jan 2021 - Jun 2021</div>
    <p>Position: Engineering Intern for Object Detection and Segmentation.
</li>
</ul>
 -->


<!-- <div id="Academic Services" class='xtitle' >Academic Services</div>
<ul class="news" style="list-style: 2em;">
<li> 
    Conference Reviewer: 
    NeurIPS ('24, '25), ICCV'25, ICML'25, ICLR'25, AAAI'25, CVPR ('24, '25), ECCV'24, NeurIPS'24, ACM MM ('24, '25)
</li>
<li> 
    Journal Reviewer: 
    TPAMI, TIFS, TCSVT, TMM, SPL
</li>
</ul> -->

<div id="Contact" class='xtitle' >Contact</div>
<ul class="news" style="list-style: none;">
<a href="yanzhiyuan1114@gmail.com">yanzhiyuan1114@gmail.com</a>; <a href="zhiyuanyan@stu.pku.edu.cn">zhiyuanyan@stu.pku.edu.cn</a>
</ul>
